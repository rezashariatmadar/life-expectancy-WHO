{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b43fd07",
   "metadata": {},
   "source": [
    "## WHO Life Expectancy Dataset - Phase 2A: Smart Data Preprocessing\n",
    "### - Based on comprehensive EDA insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6896c1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 2A: SMART DATA PREPROCESSING\n",
      "================================================================================\n",
      "ğŸ“Š Initial Dataset: 2938 records, 22 features\n",
      "ğŸ“… Time period: 2000-2015\n",
      "ğŸŒ Countries: 193\n",
      "\n",
      "ğŸ” MISSING DATA ANALYSIS\n",
      "--------------------------------------------------\n",
      "HIGH PRIORITY (>15% missing):\n",
      "  ğŸ“Š Population: 652 (22.2%)\n",
      "  ğŸ“Š Hepatitis B: 553 (18.8%)\n",
      "  ğŸ“Š GDP: 448 (15.2%)\n",
      "\n",
      "MEDIUM PRIORITY (5-15% missing):\n",
      "  ğŸ“ˆ Total expenditure: 226 (7.7%)\n",
      "  ğŸ“ˆ Alcohol: 194 (6.6%)\n",
      "  ğŸ“ˆ Income composition of resources: 167 (5.7%)\n",
      "  ğŸ“ˆ Schooling: 163 (5.5%)\n",
      "\n",
      "ğŸŒ REGIONAL MAPPING CREATION\n",
      "--------------------------------------------------\n",
      "Regional Distribution:\n",
      "  ğŸ—ºï¸ Asia: 36 countries, avg life expectancy: 70.5 years\n",
      "  ğŸ—ºï¸ Europe: 31 countries, avg life expectancy: 79.0 years\n",
      "  ğŸ—ºï¸ Africa: 31 countries, avg life expectancy: 57.3 years\n",
      "  ğŸ—ºï¸ Other/Oceania: 71 countries, avg life expectancy: 67.7 years\n",
      "  ğŸ—ºï¸ Americas: 24 countries, avg life expectancy: 74.0 years\n",
      "\n",
      "ğŸ”§ SMART MISSING DATA IMPUTATION\n",
      "--------------------------------------------------\n",
      "ğŸ“Š HIGH PRIORITY IMPUTATION:\n",
      "  ğŸ™ï¸ Population: Regional median imputation\n",
      "  ğŸ’‰ Hepatitis B: Development status-aware imputation\n",
      "  ğŸ’° GDP: Regional economic trend interpolation\n",
      "\n",
      "ğŸ“ˆ MEDIUM PRIORITY IMPUTATION:\n",
      "  ğŸ“‹ Total expenditure: Forward/backward fill by country with regional fallback\n",
      "  ğŸ“‹ Alcohol: Forward/backward fill by country with regional fallback\n",
      "  ğŸ“‹ Income composition of resources: Forward/backward fill by country with regional fallback\n",
      "  ğŸ“‹ Schooling: Forward/backward fill by country with regional fallback\n",
      "\n",
      "ğŸ“‰ LOW PRIORITY IMPUTATION:\n",
      "  ğŸ“‹ BMI: Global median imputation\n",
      "  ğŸ“‹ thinness  1-19 years: Global median imputation\n",
      "  ğŸ“‹ thinness 5-9 years: Global median imputation\n",
      "  ğŸ“‹ Polio: Global median imputation\n",
      "  ğŸ“‹ Diphtheria: Global median imputation\n",
      "\n",
      "âœ… IMPUTATION SUMMARY:\n",
      "Remaining missing values:\n",
      "  âš ï¸ Life expectancy: 10 (0.3%)\n",
      "  âš ï¸ Adult Mortality: 10 (0.3%)\n",
      "\n",
      "ğŸ”¬ FEATURE ENGINEERING\n",
      "--------------------------------------------------\n",
      "ğŸ¥ Creating Health Access Index...\n",
      "  âœ… Health Access Index created (range: 0.10-1.00)\n",
      "ğŸ“ Creating Education-Economy Index...\n",
      "  âœ… Education-Economy Index created (range: 0.00-0.99)\n",
      "ğŸ’‰ Creating Vaccination Coverage Index...\n",
      "  âœ… Vaccination Coverage Index created (range: 7.0-99.0)\n",
      "ğŸ—ºï¸ Creating Regional dummy variables...\n",
      "  âœ… Regional dummies created: ['Region_Africa', 'Region_Americas', 'Region_Asia', 'Region_Europe', 'Region_Other/Oceania']\n",
      "ğŸ­ Encoding Development Status...\n",
      "  âœ… Development Status encoded (Developed=1, Developing=0)\n",
      "ğŸ“… Creating Time-based features...\n",
      "  âœ… Time features created: Years_Since_2000, Year_Squared\n",
      "\n",
      "âœ… FEATURE ENGINEERING COMPLETE\n",
      "ğŸ“Š New dataset shape: (2938, 34)\n",
      "\n",
      "ğŸ¯ FEATURE SELECTION\n",
      "--------------------------------------------------\n",
      "ğŸ¥‡ TIER 1 FEATURES (Highest Importance):\n",
      "  âœ… Schooling (correlation: 0.679)\n",
      "  âœ… Adult Mortality (correlation: -0.696)\n",
      "  âœ… HIV/AIDS (correlation: -0.557)\n",
      "\n",
      "ğŸ¥ˆ TIER 2 FEATURES (Strong Predictors):\n",
      "  âœ… Income composition of resources (correlation: 0.677)\n",
      "  âœ… BMI (correlation: 0.559)\n",
      "  âœ… GDP (correlation: 0.433)\n",
      "\n",
      "ğŸ¥‰ TIER 3 FEATURES (Moderate Predictors):\n",
      "  âœ… Hepatitis B (correlation: 0.185)\n",
      "  âœ… Polio (correlation: 0.459)\n",
      "  âœ… Diphtheria (correlation: 0.473)\n",
      "  âœ… percentage expenditure (correlation: 0.382)\n",
      "\n",
      "ğŸ”¬ ENGINEERED FEATURES:\n",
      "  âœ… Health_Access_Index (correlation: 0.731)\n",
      "  âœ… Education_Economy_Index (correlation: 0.712)\n",
      "  âœ… Vaccination_Coverage_Index (correlation: 0.458)\n",
      "\n",
      "ğŸ—ºï¸ REGIONAL & CATEGORICAL FEATURES:\n",
      "  âœ… Region_Africa\n",
      "  âœ… Region_Americas\n",
      "  âœ… Region_Asia\n",
      "  âœ… Region_Europe\n",
      "  âœ… Region_Other/Oceania\n",
      "  âœ… Status_Developed\n",
      "  âœ… Years_Since_2000\n",
      "\n",
      "âŒ FEATURES REMOVED (High Multicollinearity):\n",
      "  ğŸ—‘ï¸ under-five deaths (removed due to multicollinearity)\n",
      "  ğŸ—‘ï¸ infant deaths (removed due to multicollinearity)\n",
      "\n",
      "âœ… FEATURE SELECTION COMPLETE\n",
      "ğŸ“Š Original features: 34\n",
      "ğŸ“Š Selected features: 25\n",
      "ğŸ“Š Final dataset shape: (2938, 25)\n",
      "\n",
      "ğŸ“‹ PREPROCESSING REPORT\n",
      "================================================================================\n",
      "ğŸ“Š DATA TRANSFORMATION SUMMARY:\n",
      "  Original dataset: (2938, 22)\n",
      "  Final dataset: (2938, 25)\n",
      "  Records retained: 2,938 (100.0%)\n",
      "\n",
      "ğŸ” MISSING DATA RESOLUTION:\n",
      "  Original missing values: 2,563\n",
      "  Final missing values: 20\n",
      "  Missing data reduction: 99.2%\n",
      "\n",
      "ğŸ¯ FEATURE ENGINEERING:\n",
      "  New features created: 11\n",
      "    âœ… Region\n",
      "    âœ… Health_Access_Index\n",
      "    âœ… Education_Economy_Index\n",
      "    âœ… Vaccination_Coverage_Index\n",
      "    âœ… Region_Africa\n",
      "    âœ… Region_Americas\n",
      "    âœ… Region_Asia\n",
      "    âœ… Region_Europe\n",
      "    âœ… Region_Other/Oceania\n",
      "    âœ… Status_Developed\n",
      "    âœ… Years_Since_2000\n",
      "\n",
      "ğŸ† READY FOR MODELING:\n",
      "  âœ… Missing data handled strategically\n",
      "  âœ… Features engineered based on EDA insights\n",
      "  âœ… Feature selection implemented\n",
      "  âœ… Regional and categorical encoding complete\n",
      "  âœ… Dataset optimized for regression modeling\n",
      "\n",
      "ğŸ’¾ Processed dataset saved as 'Life_Expectancy_Processed.csv'\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ PHASE 2A PREPROCESSING COMPLETED!\n",
      "================================================================================\n",
      "âœ… Ready for Phase 2B: Quick Model Validation\n",
      "ğŸš€ Next step: Build baseline models to test EDA predictions\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# WHO Life Expectancy Dataset - Phase 2A: Smart Data Preprocessing\n",
    "# Based on comprehensive EDA insights\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up visualization parameters\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class LifeExpectancyPreprocessor:\n",
    "    \"\"\"\n",
    "    Comprehensive preprocessing pipeline for WHO Life Expectancy data\n",
    "    Based on EDA insights from comprehensive analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.regional_mapping = {}\n",
    "        self.preprocessing_report = {}\n",
    "        \n",
    "    def load_and_setup_data(self):\n",
    "        \"\"\"Load data and perform initial setup\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"PHASE 2A: SMART DATA PREPROCESSING\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Load the data\n",
    "        df = pd.read_csv('../Life Expectancy Data.csv')\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        print(f\"ğŸ“Š Initial Dataset: {df.shape[0]} records, {df.shape[1]} features\")\n",
    "        print(f\"ğŸ“… Time period: {df['Year'].min()}-{df['Year'].max()}\")\n",
    "        print(f\"ğŸŒ Countries: {df['Country'].nunique()}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def analyze_missing_data_patterns(self, df):\n",
    "        \"\"\"Analyze missing data patterns based on EDA insights\"\"\"\n",
    "        print(f\"\\nğŸ” MISSING DATA ANALYSIS\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        missing_summary = pd.DataFrame({\n",
    "            'Column': df.columns,\n",
    "            'Missing_Count': df.isnull().sum(),\n",
    "            'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "            'Data_Type': df.dtypes\n",
    "        }).sort_values('Missing_Percentage', ascending=False)\n",
    "        \n",
    "        high_missing = missing_summary[missing_summary['Missing_Percentage'] > 15]\n",
    "        medium_missing = missing_summary[(missing_summary['Missing_Percentage'] >= 5) & \n",
    "                                       (missing_summary['Missing_Percentage'] <= 15)]\n",
    "        \n",
    "        print(\"HIGH PRIORITY (>15% missing):\")\n",
    "        for _, row in high_missing.iterrows():\n",
    "            if row['Missing_Count'] > 0:\n",
    "                print(f\"  ğŸ“Š {row['Column']}: {row['Missing_Count']} ({row['Missing_Percentage']:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nMEDIUM PRIORITY (5-15% missing):\")\n",
    "        for _, row in medium_missing.iterrows():\n",
    "            if row['Missing_Count'] > 0:\n",
    "                print(f\"  ğŸ“ˆ {row['Column']}: {row['Missing_Count']} ({row['Missing_Percentage']:.1f}%)\")\n",
    "        \n",
    "        return missing_summary\n",
    "    \n",
    "    def create_regional_mapping(self, df):\n",
    "        \"\"\"Create regional mapping based on EDA insights\"\"\"\n",
    "        print(f\"\\nğŸŒ REGIONAL MAPPING CREATION\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        def assign_region(country):\n",
    "            africa_keywords = ['Algeria', 'Angola', 'Botswana', 'Burkina', 'Burundi', 'Cameroon', 'Chad', 'Congo', \n",
    "                              'Ethiopia', 'Ghana', 'Kenya', 'Madagascar', 'Malawi', 'Mali', 'Morocco', 'Niger', \n",
    "                              'Nigeria', 'Rwanda', 'Senegal', 'Sierra Leone', 'Somalia', 'South Africa', 'Sudan', \n",
    "                              'Tanzania', 'Togo', 'Tunisia', 'Uganda', 'Zambia', 'Zimbabwe']\n",
    "            europe_keywords = ['Albania', 'Austria', 'Belgium', 'Croatia', 'Cyprus', 'Czech', 'Denmark', 'Estonia', \n",
    "                              'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', \n",
    "                              'Latvia', 'Lithuania', 'Luxembourg', 'Malta', 'Netherlands', 'Norway', 'Poland', \n",
    "                              'Portugal', 'Romania', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', \n",
    "                              'United Kingdom']\n",
    "            asia_keywords = ['Afghanistan', 'Bangladesh', 'Bhutan', 'Cambodia', 'China', 'India', 'Indonesia', \n",
    "                            'Iran', 'Iraq', 'Japan', 'Jordan', 'Kazakhstan', 'Kuwait', 'Kyrgyzstan', 'Laos', \n",
    "                            'Lebanon', 'Malaysia', 'Maldives', 'Mongolia', 'Myanmar', 'Nepal', 'Oman', 'Pakistan', \n",
    "                            'Philippines', 'Qatar', 'Saudi Arabia', 'Singapore', 'Sri Lanka', 'Syria', 'Tajikistan', \n",
    "                            'Thailand', 'Turkey', 'Turkmenistan', 'United Arab Emirates', 'Uzbekistan', 'Viet Nam', 'Yemen']\n",
    "            americas_keywords = ['Argentina', 'Bolivia', 'Brazil', 'Canada', 'Chile', 'Colombia', 'Costa Rica', \n",
    "                               'Cuba', 'Dominican Republic', 'Ecuador', 'El Salvador', 'Guatemala', 'Haiti', \n",
    "                               'Honduras', 'Jamaica', 'Mexico', 'Nicaragua', 'Panama', 'Paraguay', 'Peru', \n",
    "                               'Trinidad and Tobago', 'United States', 'Uruguay', 'Venezuela']\n",
    "            \n",
    "            if any(keyword in country for keyword in africa_keywords):\n",
    "                return 'Africa'\n",
    "            elif any(keyword in country for keyword in europe_keywords):\n",
    "                return 'Europe'\n",
    "            elif any(keyword in country for keyword in asia_keywords):\n",
    "                return 'Asia'\n",
    "            elif any(keyword in country for keyword in americas_keywords):\n",
    "                return 'Americas'\n",
    "            else:\n",
    "                return 'Other/Oceania'\n",
    "        \n",
    "        df['Region'] = df['Country'].apply(assign_region)\n",
    "        \n",
    "        # Store regional mapping for later use\n",
    "        self.regional_mapping = df.groupby('Region')['Country'].unique().to_dict()\n",
    "        \n",
    "        regional_stats = df.groupby('Region').agg({\n",
    "            'Life expectancy': ['count', 'mean'],\n",
    "            'Country': 'nunique'\n",
    "        }).round(2)\n",
    "        \n",
    "        print(\"Regional Distribution:\")\n",
    "        for region in df['Region'].unique():\n",
    "            count = df[df['Region'] == region]['Country'].nunique()\n",
    "            avg_life_exp = df[df['Region'] == region]['Life expectancy'].mean()\n",
    "            print(f\"  ğŸ—ºï¸ {region}: {count} countries, avg life expectancy: {avg_life_exp:.1f} years\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def implement_smart_missing_data_strategy(self, df):\n",
    "        \"\"\"Implement missing data strategy based on EDA insights\"\"\"\n",
    "        print(f\"\\nğŸ”§ SMART MISSING DATA IMPUTATION\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        df_imputed = df.copy()\n",
    "        \n",
    "        # High Priority Imputation (>15% missing)\n",
    "        print(\"ğŸ“Š HIGH PRIORITY IMPUTATION:\")\n",
    "        \n",
    "        # 1. Population (22% missing) - Regional imputation\n",
    "        if 'Population' in df_imputed.columns:\n",
    "            print(\"  ğŸ™ï¸ Population: Regional median imputation\")\n",
    "            for region in df_imputed['Region'].unique():\n",
    "                mask = (df_imputed['Region'] == region) & df_imputed['Population'].isnull()\n",
    "                if mask.sum() > 0:\n",
    "                    regional_median = df_imputed[df_imputed['Region'] == region]['Population'].median()\n",
    "                    df_imputed.loc[mask, 'Population'] = regional_median\n",
    "        \n",
    "        # 2. Hepatitis B (19% missing) - Development status aware\n",
    "        if 'Hepatitis B' in df_imputed.columns:\n",
    "            print(\"  ğŸ’‰ Hepatitis B: Development status-aware imputation\")\n",
    "            for status in df_imputed['Status'].unique():\n",
    "                mask = (df_imputed['Status'] == status) & df_imputed['Hepatitis B'].isnull()\n",
    "                if mask.sum() > 0:\n",
    "                    status_median = df_imputed[df_imputed['Status'] == status]['Hepatitis B'].median()\n",
    "                    df_imputed.loc[mask, 'Hepatitis B'] = status_median\n",
    "        \n",
    "        # 3. GDP (15% missing) - Economic trend interpolation\n",
    "        if 'GDP' in df_imputed.columns:\n",
    "            print(\"  ğŸ’° GDP: Regional economic trend interpolation\")\n",
    "            for region in df_imputed['Region'].unique():\n",
    "                region_data = df_imputed[df_imputed['Region'] == region].copy()\n",
    "                if region_data['GDP'].isnull().sum() > 0:\n",
    "                    # Use KNN imputation within region\n",
    "                    region_features = ['Year', 'percentage expenditure', 'Total expenditure']\n",
    "                    available_features = [f for f in region_features if f in region_data.columns]\n",
    "                    \n",
    "                    if len(available_features) > 1:\n",
    "                        imputer = KNNImputer(n_neighbors=3)\n",
    "                        region_data_subset = region_data[available_features + ['GDP']].copy()\n",
    "                        imputed_values = imputer.fit_transform(region_data_subset)\n",
    "                        df_imputed.loc[df_imputed['Region'] == region, 'GDP'] = imputed_values[:, -1]\n",
    "        \n",
    "        # Medium Priority Imputation (5-15% missing)\n",
    "        print(\"\\nğŸ“ˆ MEDIUM PRIORITY IMPUTATION:\")\n",
    "        medium_priority_cols = ['Total expenditure', 'Alcohol', 'Income composition of resources', 'Schooling']\n",
    "        \n",
    "        for col in medium_priority_cols:\n",
    "            if col in df_imputed.columns and df_imputed[col].isnull().sum() > 0:\n",
    "                print(f\"  ğŸ“‹ {col}: Forward/backward fill by country with regional fallback\")\n",
    "                # Forward fill by country, then regional median\n",
    "                df_imputed[col] = df_imputed.groupby('Country')[col].fillna(method='ffill').fillna(method='bfill')\n",
    "                \n",
    "                # Regional median for remaining missing values\n",
    "                for region in df_imputed['Region'].unique():\n",
    "                    mask = (df_imputed['Region'] == region) & df_imputed[col].isnull()\n",
    "                    if mask.sum() > 0:\n",
    "                        regional_median = df_imputed[df_imputed['Region'] == region][col].median()\n",
    "                        df_imputed.loc[mask, col] = regional_median\n",
    "        \n",
    "        # Low Priority Imputation (<5% missing)\n",
    "        print(\"\\nğŸ“‰ LOW PRIORITY IMPUTATION:\")\n",
    "        low_priority_cols = ['BMI', 'thinness  1-19 years', 'thinness 5-9 years', 'Polio', 'Diphtheria']\n",
    "        \n",
    "        for col in low_priority_cols:\n",
    "            if col in df_imputed.columns and df_imputed[col].isnull().sum() > 0:\n",
    "                print(f\"  ğŸ“‹ {col}: Global median imputation\")\n",
    "                df_imputed[col].fillna(df_imputed[col].median(), inplace=True)\n",
    "        \n",
    "        # Report imputation results\n",
    "        print(f\"\\nâœ… IMPUTATION SUMMARY:\")\n",
    "        remaining_missing = df_imputed.isnull().sum()\n",
    "        remaining_missing = remaining_missing[remaining_missing > 0]\n",
    "        \n",
    "        if len(remaining_missing) > 0:\n",
    "            print(\"Remaining missing values:\")\n",
    "            for col, count in remaining_missing.items():\n",
    "                percentage = (count / len(df_imputed)) * 100\n",
    "                print(f\"  âš ï¸ {col}: {count} ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            print(\"ğŸ‰ All missing values successfully imputed!\")\n",
    "        \n",
    "        return df_imputed\n",
    "    \n",
    "    def create_feature_engineered_variables(self, df):\n",
    "        \"\"\"Create feature-engineered variables based on EDA insights\"\"\"\n",
    "        print(f\"\\nğŸ”¬ FEATURE ENGINEERING\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        df_engineered = df.copy()\n",
    "        \n",
    "        # 1. Health Access Index (Adult Mortality + healthcare indicators)\n",
    "        print(\"ğŸ¥ Creating Health Access Index...\")\n",
    "        health_indicators = ['Adult Mortality', 'HIV/AIDS']\n",
    "        available_health = [col for col in health_indicators if col in df_engineered.columns]\n",
    "        \n",
    "        if len(available_health) >= 2:\n",
    "            # Normalize and create inverse index (lower is better for mortality/disease)\n",
    "            health_normalized = df_engineered[available_health].copy()\n",
    "            for col in available_health:\n",
    "                health_normalized[col] = 1 - (health_normalized[col] - health_normalized[col].min()) / (health_normalized[col].max() - health_normalized[col].min())\n",
    "            df_engineered['Health_Access_Index'] = health_normalized.mean(axis=1)\n",
    "            print(f\"  âœ… Health Access Index created (range: {df_engineered['Health_Access_Index'].min():.2f}-{df_engineered['Health_Access_Index'].max():.2f})\")\n",
    "        \n",
    "        # 2. Education-Economy Index (Schooling + Income Composition)\n",
    "        print(\"ğŸ“ Creating Education-Economy Index...\")\n",
    "        edu_econ_indicators = ['Schooling', 'Income composition of resources']\n",
    "        available_edu_econ = [col for col in edu_econ_indicators if col in df_engineered.columns]\n",
    "        \n",
    "        if len(available_edu_econ) >= 2:\n",
    "            # Normalize and create composite index\n",
    "            edu_econ_normalized = df_engineered[available_edu_econ].copy()\n",
    "            for col in available_edu_econ:\n",
    "                edu_econ_normalized[col] = (edu_econ_normalized[col] - edu_econ_normalized[col].min()) / (edu_econ_normalized[col].max() - edu_econ_normalized[col].min())\n",
    "            df_engineered['Education_Economy_Index'] = edu_econ_normalized.mean(axis=1)\n",
    "            print(f\"  âœ… Education-Economy Index created (range: {df_engineered['Education_Economy_Index'].min():.2f}-{df_engineered['Education_Economy_Index'].max():.2f})\")\n",
    "        \n",
    "        # 3. Vaccination Coverage Index\n",
    "        print(\"ğŸ’‰ Creating Vaccination Coverage Index...\")\n",
    "        vaccination_cols = ['Hepatitis B', 'Polio', 'Diphtheria']\n",
    "        available_vaccines = [col for col in vaccination_cols if col in df_engineered.columns]\n",
    "        \n",
    "        if len(available_vaccines) >= 2:\n",
    "            # Average vaccination coverage\n",
    "            df_engineered['Vaccination_Coverage_Index'] = df_engineered[available_vaccines].mean(axis=1)\n",
    "            print(f\"  âœ… Vaccination Coverage Index created (range: {df_engineered['Vaccination_Coverage_Index'].min():.1f}-{df_engineered['Vaccination_Coverage_Index'].max():.1f})\")\n",
    "        \n",
    "        # 4. Regional dummy variables (based on EDA insights)\n",
    "        print(\"ğŸ—ºï¸ Creating Regional dummy variables...\")\n",
    "        regional_dummies = pd.get_dummies(df_engineered['Region'], prefix='Region')\n",
    "        df_engineered = pd.concat([df_engineered, regional_dummies], axis=1)\n",
    "        print(f\"  âœ… Regional dummies created: {list(regional_dummies.columns)}\")\n",
    "        \n",
    "        # 5. Development Status encoding\n",
    "        print(\"ğŸ­ Encoding Development Status...\")\n",
    "        df_engineered['Status_Developed'] = (df_engineered['Status'] == 'Developed').astype(int)\n",
    "        print(f\"  âœ… Development Status encoded (Developed=1, Developing=0)\")\n",
    "        \n",
    "        # 6. Time-based features\n",
    "        print(\"ğŸ“… Creating Time-based features...\")\n",
    "        df_engineered['Years_Since_2000'] = df_engineered['Year'] - 2000\n",
    "        df_engineered['Year_Squared'] = df_engineered['Years_Since_2000'] ** 2  # For non-linear time trends\n",
    "        print(f\"  âœ… Time features created: Years_Since_2000, Year_Squared\")\n",
    "        \n",
    "        print(f\"\\nâœ… FEATURE ENGINEERING COMPLETE\")\n",
    "        print(f\"ğŸ“Š New dataset shape: {df_engineered.shape}\")\n",
    "        \n",
    "        return df_engineered\n",
    "    \n",
    "    def implement_feature_selection(self, df):\n",
    "        \"\"\"Implement feature selection based on EDA insights\"\"\"\n",
    "        print(f\"\\nğŸ¯ FEATURE SELECTION\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Based on EDA insights - feature importance ranking\n",
    "        tier1_features = ['Schooling', 'Adult Mortality', 'HIV/AIDS']\n",
    "        tier2_features = ['Income composition of resources', 'BMI', 'GDP']\n",
    "        tier3_features = ['Hepatitis B', 'Polio', 'Diphtheria', 'percentage expenditure']\n",
    "        \n",
    "        # Engineered features\n",
    "        engineered_features = ['Health_Access_Index', 'Education_Economy_Index', 'Vaccination_Coverage_Index']\n",
    "        \n",
    "        # Regional and categorical features\n",
    "        regional_features = [col for col in df.columns if col.startswith('Region_')]\n",
    "        categorical_features = ['Status_Developed', 'Years_Since_2000']\n",
    "        \n",
    "        # Features to remove based on EDA (high multicollinearity)\n",
    "        remove_features = ['under-five deaths', 'infant deaths']  # Keep only infant deaths (0.997 correlation)\n",
    "        \n",
    "        # Combine selected features\n",
    "        selected_features = []\n",
    "        \n",
    "        print(\"ğŸ¥‡ TIER 1 FEATURES (Highest Importance):\")\n",
    "        for feature in tier1_features:\n",
    "            if feature in df.columns:\n",
    "                selected_features.append(feature)\n",
    "                correlation = df[feature].corr(df['Life expectancy']) if 'Life expectancy' in df.columns else 'N/A'\n",
    "                print(f\"  âœ… {feature} (correlation: {correlation:.3f})\")\n",
    "        \n",
    "        print(\"\\nğŸ¥ˆ TIER 2 FEATURES (Strong Predictors):\")\n",
    "        for feature in tier2_features:\n",
    "            if feature in df.columns:\n",
    "                selected_features.append(feature)\n",
    "                correlation = df[feature].corr(df['Life expectancy']) if 'Life expectancy' in df.columns else 'N/A'\n",
    "                print(f\"  âœ… {feature} (correlation: {correlation:.3f})\")\n",
    "        \n",
    "        print(\"\\nğŸ¥‰ TIER 3 FEATURES (Moderate Predictors):\")\n",
    "        for feature in tier3_features:\n",
    "            if feature in df.columns:\n",
    "                selected_features.append(feature)\n",
    "                correlation = df[feature].corr(df['Life expectancy']) if 'Life expectancy' in df.columns else 'N/A'\n",
    "                print(f\"  âœ… {feature} (correlation: {correlation:.3f})\")\n",
    "        \n",
    "        print(\"\\nğŸ”¬ ENGINEERED FEATURES:\")\n",
    "        for feature in engineered_features:\n",
    "            if feature in df.columns:\n",
    "                selected_features.append(feature)\n",
    "                correlation = df[feature].corr(df['Life expectancy']) if 'Life expectancy' in df.columns else 'N/A'\n",
    "                print(f\"  âœ… {feature} (correlation: {correlation:.3f})\")\n",
    "        \n",
    "        print(\"\\nğŸ—ºï¸ REGIONAL & CATEGORICAL FEATURES:\")\n",
    "        selected_features.extend(regional_features)\n",
    "        selected_features.extend(categorical_features)\n",
    "        for feature in regional_features + categorical_features:\n",
    "            if feature in df.columns:\n",
    "                print(f\"  âœ… {feature}\")\n",
    "        \n",
    "        print(\"\\nâŒ FEATURES REMOVED (High Multicollinearity):\")\n",
    "        for feature in remove_features:\n",
    "            if feature in df.columns:\n",
    "                print(f\"  ğŸ—‘ï¸ {feature} (removed due to multicollinearity)\")\n",
    "        \n",
    "        # Always include target variable and identifiers\n",
    "        essential_features = ['Country', 'Year', 'Life expectancy', 'Status', 'Region']\n",
    "        all_features = essential_features + selected_features\n",
    "        \n",
    "        # Remove duplicates and ensure features exist\n",
    "        final_features = []\n",
    "        for feature in all_features:\n",
    "            if feature in df.columns and feature not in final_features:\n",
    "                final_features.append(feature)\n",
    "        \n",
    "        # Create final dataset\n",
    "        df_final = df[final_features].copy()\n",
    "        \n",
    "        print(f\"\\nâœ… FEATURE SELECTION COMPLETE\")\n",
    "        print(f\"ğŸ“Š Original features: {df.shape[1]}\")\n",
    "        print(f\"ğŸ“Š Selected features: {len(final_features)}\")\n",
    "        print(f\"ğŸ“Š Final dataset shape: {df_final.shape}\")\n",
    "        \n",
    "        return df_final, final_features\n",
    "    \n",
    "    def generate_preprocessing_report(self, original_df, final_df):\n",
    "        \"\"\"Generate comprehensive preprocessing report\"\"\"\n",
    "        print(f\"\\nğŸ“‹ PREPROCESSING REPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(f\"ğŸ“Š DATA TRANSFORMATION SUMMARY:\")\n",
    "        print(f\"  Original dataset: {original_df.shape}\")\n",
    "        print(f\"  Final dataset: {final_df.shape}\")\n",
    "        print(f\"  Records retained: {len(final_df):,} ({len(final_df)/len(original_df)*100:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nğŸ” MISSING DATA RESOLUTION:\")\n",
    "        original_missing = original_df.isnull().sum().sum()\n",
    "        final_missing = final_df.isnull().sum().sum()\n",
    "        print(f\"  Original missing values: {original_missing:,}\")\n",
    "        print(f\"  Final missing values: {final_missing:,}\")\n",
    "        print(f\"  Missing data reduction: {((original_missing - final_missing) / original_missing * 100):.1f}%\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ FEATURE ENGINEERING:\")\n",
    "        new_features = [col for col in final_df.columns if col not in original_df.columns]\n",
    "        print(f\"  New features created: {len(new_features)}\")\n",
    "        for feature in new_features:\n",
    "            print(f\"    âœ… {feature}\")\n",
    "        \n",
    "        print(f\"\\nğŸ† READY FOR MODELING:\")\n",
    "        print(f\"  âœ… Missing data handled strategically\")\n",
    "        print(f\"  âœ… Features engineered based on EDA insights\") \n",
    "        print(f\"  âœ… Feature selection implemented\")\n",
    "        print(f\"  âœ… Regional and categorical encoding complete\")\n",
    "        print(f\"  âœ… Dataset optimized for regression modeling\")\n",
    "        \n",
    "        return {\n",
    "            'original_shape': original_df.shape,\n",
    "            'final_shape': final_df.shape,\n",
    "            'missing_reduction': ((original_missing - final_missing) / original_missing * 100),\n",
    "            'new_features': new_features,\n",
    "            'records_retained': len(final_df)/len(original_df)*100\n",
    "        }\n",
    "\n",
    "def run_preprocessing_pipeline():\n",
    "    \"\"\"Run the complete preprocessing pipeline\"\"\"\n",
    "    \n",
    "    # Initialize preprocessor\n",
    "    preprocessor = LifeExpectancyPreprocessor()\n",
    "    \n",
    "    # Step 1: Load and setup data\n",
    "    df = preprocessor.load_and_setup_data()\n",
    "    original_df = df.copy()\n",
    "    \n",
    "    # Step 2: Analyze missing data patterns\n",
    "    missing_summary = preprocessor.analyze_missing_data_patterns(df)\n",
    "    \n",
    "    # Step 3: Create regional mapping\n",
    "    df = preprocessor.create_regional_mapping(df)\n",
    "    \n",
    "    # Step 4: Implement smart missing data strategy\n",
    "    df = preprocessor.implement_smart_missing_data_strategy(df)\n",
    "    \n",
    "    # Step 5: Create feature-engineered variables\n",
    "    df = preprocessor.create_feature_engineered_variables(df)\n",
    "    \n",
    "    # Step 6: Implement feature selection\n",
    "    df_final, selected_features = preprocessor.implement_feature_selection(df)\n",
    "    \n",
    "    # Step 7: Generate preprocessing report\n",
    "    report = preprocessor.generate_preprocessing_report(original_df, df_final)\n",
    "    \n",
    "    # Save processed dataset\n",
    "    df_final.to_csv('Life_Expectancy_Processed.csv', index=False)\n",
    "    print(f\"\\nğŸ’¾ Processed dataset saved as 'Life_Expectancy_Processed.csv'\")\n",
    "    \n",
    "    return df_final, selected_features, report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete preprocessing pipeline\n",
    "    processed_df, features, preprocessing_report = run_preprocessing_pipeline()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ‰ PHASE 2A PREPROCESSING COMPLETED!\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"âœ… Ready for Phase 2B: Quick Model Validation\")\n",
    "    print(\"ğŸš€ Next step: Build baseline models to test EDA predictions\")\n",
    "    print(\"=\"*80) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
